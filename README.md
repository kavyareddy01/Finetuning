# Finetuning LLM Models

## **1. Model Quantization**

Definition : Conversion from higher memory format to a lower memory format
Ex : 

* Full Precision/Half Precision

   DATA -> Weights and Parameters
  
* Calibration - Model Quantization
* Modes of Quantization
   -> Post Training Quantization
   -> Quantization Aware Training
